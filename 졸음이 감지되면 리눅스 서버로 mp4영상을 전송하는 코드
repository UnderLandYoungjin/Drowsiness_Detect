import cv2
import mediapipe as mp
import numpy as np
from datetime import datetime
import os
import paramiko

# Mediapipe 설정
mp_face_mesh = mp.solutions.face_mesh

# EAR 임계값 및 Cpoint 설정
EAR_THRESHOLD = 0.225
CPOINT_THRESHOLD = 0.5  # 예시 값 (Cpoint 기준값은 실제 조건에 맞게 설정)
FPS = 20  # 초당 프레임 수 (웹캠 설정에 맞춰 조정)

# 비디오 버퍼 초기화 (최근 30초간 프레임 저장)
BUFFER_SECONDS = 30
buffer_size = BUFFER_SECONDS * FPS
video_buffer = []

# 서버 정보 설정
SERVER_IP = "xxx.xxx.xxx"
USERNAME = "id"
PASSWORD = "pass"
REMOTE_FOLDER = "/home/hyj/test_mp"

# 눈 랜드마크 인덱스
LEFT_EYE_IDX = [33, 160, 158, 133, 153, 144]
RIGHT_EYE_IDX = [362, 385, 387, 263, 373, 380]

# EAR 계산 함수
def eye_aspect_ratio(eye_points):
    def euclidean_distance(p1, p2):
        return np.linalg.norm(p1 - p2)

    ear_left = (euclidean_distance(eye_points[1], eye_points[5]) +
                euclidean_distance(eye_points[2], eye_points[4])) / (2.0 * euclidean_distance(eye_points[0], eye_points[3]))
    return ear_left

# 영상 캡처 시작
cap = cv2.VideoCapture(0)
frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

# Face Mesh 초기화
with mp_face_mesh.FaceMesh(
    max_num_faces=1,
    refine_landmarks=True,
    min_detection_confidence=0.5,
    min_tracking_confidence=0.5
) as face_mesh:

    drowsy_detected = False
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        result = face_mesh.process(frame_rgb)
        frame_height, frame_width = frame.shape[:2]

        # 얼굴 랜드마크 확인
        if result.multi_face_landmarks:
            for face_landmarks in result.multi_face_landmarks:
                left_eye_points = np.array([[face_landmarks.landmark[idx].x * frame_width,
                                             face_landmarks.landmark[idx].y * frame_height] for idx in LEFT_EYE_IDX])
                right_eye_points = np.array([[face_landmarks.landmark[idx].x * frame_width,
                                              face_landmarks.landmark[idx].y * frame_height] for idx in RIGHT_EYE_IDX])

                ear_value = eye_aspect_ratio(np.concatenate((left_eye_points, right_eye_points), axis=0))

                # Cpoint는 예시값, 실제 데이터에 맞춰 설정 필요
                cpoint_value = np.random.rand()  # Cpoint 예시 값 (실제 Cpoint 계산으로 대체)

                # 졸음 탐지 조건
                if ear_value < EAR_THRESHOLD and cpoint_value > CPOINT_THRESHOLD:
                    drowsy_detected = True
                    print("졸음 탐지됨")

                    # 30초간의 버퍼된 비디오를 저장
                    if len(video_buffer) >= buffer_size:
                        # 파일 이름 설정
                        timestamp = datetime.now().strftime('%Y%m%d%H%M%S')
                        filename = f"es_{timestamp}.mp4"
                        filepath = os.path.join("/tmp", filename)

                        # 비디오 파일 저장
                        out = cv2.VideoWriter(filepath, cv2.VideoWriter_fourcc(*'mp4v'), FPS, (frame_width, frame_height))
                        for buffered_frame in video_buffer:
                            out.write(buffered_frame)
                        out.release()

                        # 파일 전송 (paramiko 사용)
                        try:
                            # SSH 클라이언트 설정
                            ssh_client = paramiko.SSHClient()
                            ssh_client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
                            ssh_client.connect(SERVER_IP, username=USERNAME, password=PASSWORD)

                            # SFTP를 통해 파일 전송
                            sftp = ssh_client.open_sftp()
                            sftp.put(filepath, os.path.join(REMOTE_FOLDER, filename))
                            sftp.close()
                            ssh_client.close()

                            print(f"{filename} 파일 전송 완료")
                        except Exception as e:
                            print(f"파일 전송 오류: {e}")

                        # 전송 후 버퍼 초기화 및 탐지 상태 초기화
                        video_buffer = []
                        drowsy_detected = False

                # 현재 프레임을 버퍼에 추가
                video_buffer.append(frame)
                if len(video_buffer) > buffer_size:
                    video_buffer.pop(0)

        # ESC 키로 종료
        if cv2.waitKey(1) & 0xFF == 27:
            break

cap.release()
cv2.destroyAllWindows()
