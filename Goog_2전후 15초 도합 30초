import cv2
import mediapipe as mp
import numpy as np
from PIL import Image, ImageFont, ImageDraw
import os
from datetime import datetime
import requests
import time
from collections import deque

# Mediapipe 모듈 초기화
mp_face_mesh = mp.solutions.face_mesh

# 리눅스 시스템에 맞는 폰트 경로 설정
font_path = "/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf"
font_large = ImageFont.truetype(font_path, 20)
font_small = ImageFont.truetype(font_path, 7)

# 서버 URL 설정
upload_url = 'http://000.000.000.000:0000/upload'

# 왼쪽 및 오른쪽 눈의 랜드마크 인덱스
LEFT_EYE_IDX = [33, 160, 158, 133, 153, 144]
RIGHT_EYE_IDX = [362, 385, 387, 263, 373, 380]

# EAR 계산 함수
def eye_aspect_ratio(eye_points):
    def euclidean_distance(p1, p2):
        return np.linalg.norm(p1 - p2)
    ear_left = (euclidean_distance(eye_points[1], eye_points[5]) +
                euclidean_distance(eye_points[2], eye_points[4])) / (2.0 * euclidean_distance(eye_points[0], eye_points[3]))
    ear_right = (euclidean_distance(eye_points[7], eye_points[11]) +
                 euclidean_distance(eye_points[8], eye_points[10])) / (2.0 * euclidean_distance(eye_points[6], eye_points[9]))
    return (ear_left + ear_right) / 2

# 카메라 초기화
cap = cv2.VideoCapture(0)

# 비디오 파일 초기화
FPS = 20
buffer_duration = 30  # 30초
frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
output_filename = "current_recording.mp4"

# 비디오 작성기 설정
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out = cv2.VideoWriter(output_filename, fourcc, FPS, (frame_width, frame_height))

# 졸음 탐지 상태 및 타이머 초기화
drowsy_start_time = None
recording_start_time = time.time()
sent_video = False  # 영상 전송 여부 플래그
cooldown_start_time = None  # 16초 대기 시간 플래그
recording_additional_15_seconds = False  # 추가 녹화 상태 플래그
additional_recording_start_time = None  # 추가 녹화 시작 시간

# 얼굴 중앙 좌표 히스토리
landmark_hist = deque(maxlen=600)  # 약 10분간 중앙 좌표 저장

# Face Mesh를 사용한 감지
with mp_face_mesh.FaceMesh(
    max_num_faces=1,
    refine_landmarks=True,
    min_detection_confidence=0.5,
    min_tracking_confidence=0.5
) as face_mesh:
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        # 상하 반전 및 RGB 변환
        frame = cv2.flip(frame, 0)
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        result = face_mesh.process(frame_rgb)
        frame_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        draw = ImageDraw.Draw(frame_pil)

        drowsy_detected = False  # 졸음 탐지 초기화

        # 쿨다운이 끝났다면 `sent_video`를 초기화
        if cooldown_start_time and time.time() - cooldown_start_time >= 16:
            cooldown_start_time = None  # 쿨다운 종료
            sent_video = False  # 다음 탐지를 위해 `sent_video`를 초기화

        # 얼굴 랜드마크가 감지된 경우 EAR 계산 및 시각 정보 추가
        if result.multi_face_landmarks:
            for face_landmarks in result.multi_face_landmarks:
                left_eye_points = np.array([[face_landmarks.landmark[idx].x * frame_width, 
                                             face_landmarks.landmark[idx].y * frame_height] for idx in LEFT_EYE_IDX])
                right_eye_points = np.array([[face_landmarks.landmark[idx].x * frame_width, 
                                              face_landmarks.landmark[idx].y * frame_height] for idx in RIGHT_EYE_IDX])

                ear_value = eye_aspect_ratio(np.concatenate((left_eye_points, right_eye_points), axis=0))

                # EAR 색상 설정
                ear_color = (255, 0, 0) if ear_value < 0.2 else (0, 255, 0)
                draw.text((30, 30), f'EAR: {ear_value:.2f}', font=font_large, fill=ear_color)

                # 얼굴 중앙 좌표
                face_center_x = int(face_landmarks.landmark[1].x * frame_width)
                face_center_y = int(face_landmarks.landmark[1].y * frame_height)
                landmark_hist.append((face_center_x, face_center_y))

                # 최근 중앙 좌표의 평균 좌표 계산
                avg_face_center_x = int(np.mean([point[0] for point in landmark_hist]))
                avg_face_center_y = int(np.mean([point[1] for point in landmark_hist]))

                # 중앙 좌표 간 거리 계산
                distance_between_centers = np.sqrt((avg_face_center_x - face_center_x) ** 2 +
                                                   (avg_face_center_y - face_center_y) ** 2)
                distance_color = (0, 255, 0) if distance_between_centers <= 40 else (255, 0, 0)
                draw.text((face_center_x + 10, face_center_y - 10), f'Distance: {distance_between_centers:.2f}', font=font_large, fill=distance_color)

                # 졸음 탐지 기준
                if ear_value < 0.2 and distance_between_centers > 40:
                    if drowsy_start_time is None:
                        drowsy_start_time = time.time()
                    elif time.time() - drowsy_start_time >= 1:  # 1초 경과 시 졸음 감지
                        drowsy_detected = True
                else:
                    drowsy_start_time = None

                # 눈 랜드마크 시각화
                for idx, (x, y) in enumerate(np.concatenate((left_eye_points, right_eye_points), axis=0)):
                    draw.text((x + 5, y - 5), f'p{idx+1}', font=font_small, fill=(255, 165, 0))
                    draw.ellipse((x - 2, y - 2, x + 2, y + 2), fill=(255, 165, 0))

                # 중앙 좌표와 평균 좌표 표시 및 연결 선
                draw.ellipse((face_center_x - 5, face_center_y - 5, face_center_x + 5, face_center_y + 5), fill=(255, 0, 0))
                draw.ellipse((avg_face_center_x - 5, avg_face_center_y - 5, avg_face_center_x + 5, avg_face_center_y + 5), fill=(0, 255, 255))
                draw.line([(face_center_x, face_center_y), (avg_face_center_x, avg_face_center_y)], fill=(255, 0, 0), width=2)

        # OpenCV 이미지로 변환
        frame = cv2.cvtColor(np.array(frame_pil), cv2.COLOR_RGB2BGR)

        # 프레임 기록
        out.write(frame)

        # 졸음이 감지되었고, 전송되지 않은 경우에만 추가 녹화 시작
        if drowsy_detected and not sent_video:
            sent_video = True  # 중복 전송 방지
            recording_additional_15_seconds = True
            additional_recording_start_time = time.time()
            print("졸음 감지됨: 추가 15초 녹화 시작")

        # 추가 15초 녹화가 활성화된 경우
        if recording_additional_15_seconds:
            # 추가 녹화 시간 계산
            if time.time() - additional_recording_start_time >= 15:
                recording_additional_15_seconds = False  # 추가 녹화 종료

                # 현재 저장된 30초 영상 전송 준비
                out.release()  # 비디오 작성기 해제
                timestamp = datetime.now().strftime('%Y%m%d%H%M%S')
                drowsy_filename = f"/tmp/ACACACACACACACACACACACACACAC_{timestamp}.mp4"
                os.rename(output_filename, drowsy_filename)
                print("졸음 감지 후 15초 추가 녹화 완료: 영상 전송 중")

                # 서버에 파일 전송
                with open(drowsy_filename, 'rb') as f:
                    files = {'file': f}
                    response = requests.post(upload_url, files=files)
                    if response.status_code == 200:
                        print("파일 전송 완료")
                    else:
                        print("파일 전송 실패")

                # 전송 후 임시 파일 삭제
                os.remove(drowsy_filename)

                # 새로운 녹화 시작
                out = cv2.VideoWriter(output_filename, fourcc, FPS, (frame_width, frame_height))
                cooldown_start_time = time.time()  # 쿨다운 시작

        # 화면에 결과 출력
        cv2.imshow('Drowsiness Detection', frame)

        if cv2.waitKey(5) & 0xFF == 27:
            break

# 종료 처리
out.release()
cap.release()
cv2.destroyAllWindows()
